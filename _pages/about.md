---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

‚≠ê If you have opportunities or collaborations in mind, please feel free to reach out. ‚≠ê

I am currently an Applied Research Scientist at AWS, Amazon, working on Generative AI.

I got my **Ph.D.** from [**University of Illinois at Urbana-Champaign**](https://illinois.edu/), guided by [**Prof. Naira Hovakimyan**](https://naira.mechse.illinois.edu/sciencex_teams/naira-hovakimyan/). I've also been a research scientist in machine learning at [**Intelinair**](https://www.intelinair.com/), mentored by [**Jennifer Hobbs**](https://scholar.google.com/citations?user=zeWhseAAAAAJ&hl=en). Additionally, I interned as an applied research scientist at [**Amazon**](https://www.amazon.jobs/en/teams/buyer-risk-prevention).

## üîç **Research Interests**

My research is primarily in the fields of **LLM**, **computer vision** and **multi-modality learning**. In particular, I'm interested in exploring **improved representation learning** techniques to aid machines in comprehending the structure of massive amounts of unlabeled data.

In industry applications, my efforts are devoted to **remote sensing**, **robotics** and **sustainable agriculture**. My philosophy towards research is centered around bringing people's lives and AI technology together at scale. 



<!-- Scrollable News Section -->
<div class="news-container">
  <h2>üì∞ News & Updates</h2>
  <div class="news-updates">
    <ul>
      <li><strong>May 2024</strong>: I am pleased to announce the successful defense of my Ph.D. thesis.</li>
      <li><strong>April 2024</strong>:
        <ul>
          <li>Our paper, "The new agronomists: Language models are experts in crop management" has been accepted at <strong>CVPR in AgVision</strong>.</li>
          <li>Our paper, "Residual-based Language Models are Free Boosters for Biomedical Imaging" has been accepted at <strong>CVPR in AI-MIA</strong> as <strong>oral</strong> presentation.</li>
        </ul>
      </li>
      <li><strong>Jan 2024</strong>: Our paper, "SwitchTab: Switched Autoencoders Are Effective Tabular Learners" has been accepted at <strong>AAAI</strong>.</li>
      <li><strong>Oct 2023</strong>: Our work on "ReConTab: Regularized Contrastive Representation Learning for Tabular Data" has been accepted at <strong>NeurIPS</strong> workshop.</li>
      <li><strong>September 2023</strong>: Our paper titled "Balanced Training for Sparse GANs" has been accepted at <strong>NeurIPS</strong>.</li>
      <li><strong>July 2023</strong>: 
        <ul>
          <li>Our paper, "Hallucination Improves the Performance of Contrastive Learning," got accepted at <strong>ICCV</strong>. <a href="https://arxiv.org/pdf/2307.12168.pdf">Read the paper here</a>.</li>
          <li>Our work "GenCo: An Auxiliary Generator from Contrastive Learning for Enhanced Few-Shot Learning in Remote Sensing" received the <strong>spotlight</strong> at <strong>ECAI</strong>. <a href="https://arxiv.org/pdf/2307.14612.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>May 2023</strong>: I'm joining <strong>Amazon</strong> as an Intern Applied Research Scientist.</li>
      <li><strong>April 2023</strong>: 
        <ul>
          <li>Our research on "Optimizing Crop Management with Reinforcement Learning and Imitation Learning" has been accepted at <strong>IJCAI</strong>. <a href="https://arxiv.org/pdf/2209.09991.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>March 2023</strong>: 
        <ul>
          <li>New paper on <strong>Arxiv</strong> titled "Dynamic Sparse Training for GANs". <a href="https://arxiv.org/pdf/2302.14670.pdf">Read the paper here</a>.</li>
          <li>Our work "Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis" got accepted at <strong>TMLR</strong>. <a href="https://arxiv.org/pdf/2303.02460.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>June 2022</strong>: Presented our research at <strong>CVPR</strong> in New Orleans.</li>
      <li><strong>May 2022</strong>: 
        <ul>
          <li>Our paper, "Optimizing Nitrogen Management with Deep Reinforcement Learning and Crop Simulations", was accepted for an <strong>oral</strong> presentation at <strong>CVPR in AgVision</strong>. <a href="https://arxiv.org/pdf/2204.10394.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
    </ul>
  </div>
</div>

<!-- CSS to make the news section scrollable and align with previous titles -->
<style>
  .news-container {
    margin: 20px auto;
    width: 100%; /* Align width with previous titles */
    max-width: 800px; /* Adjust width to make it wider */
  }

  .news-updates {
    height: 250px; /* Adjust height for more content */
    overflow-y: scroll; /* Enable vertical scrolling */
    padding: 10px;
    border: 1px solid #ddd;
    background-color: #f9f9f9;
  }

  .news-updates ul {
    list-style-type: none;
    padding: 0;
  }

  .news-updates li {
    margin-bottom: 15px;
  }

  .news-updates li ul {
    margin-top: 5px;
  }

  .news-updates a {
    color: #0066cc;
    text-decoration: none;
  }

  .news-updates a:hover {
    text-decoration: underline;
  }
</style>





## üìë **Selected Publications**

<div class="carousel">
  <div class="slides">
    <figure>
      <img src="images/Switch.png" alt="SwitchTab: Switched Autoencoders Are Effective Tabular Learners">
      <figcaption>
        <strong>SwitchTab: Switched Autoencoders Are Effective Tabular Learners</strong><br>
        <em>Authors: <b>Jing Wu</b>*, Suiyao Chen*, Qi Zhao,
Renat Sergazinov, Chen Li, Shengjie Liu, Chongchao Zhao, Tianpei Xie, Hanqing Guo, Cheng Ji,
Daniel Cociorva, Hakan Brunzell</em><br>
        <em>AAAI 2024 </em><br>
        <a href="https://arxiv.org/pdf/2401.02013" target="_blank">Read the paper</a>  
<!--         <a href="[Code Link]" target="_blank">Code</a> -->
      </figcaption>
    </figure>
    <figure>
      <img src="images/LLM_AG.png" alt="The New Agronomists: Language Models are Experts in Crop Management">
      <figcaption>
        <strong>The New Agronomists: Language Models are Experts in Crop Management</strong><br>
        <em>Authors: <b>Jing Wu</b>, Zhixin Lai, Suiyao Chen, Ran Tao, Pan Zhao, Naira Hovakimyan </em><br>
        <em>CVPRW 2024 </em><br>
        <a href="https://openaccess.thecvf.com/content/CVPR2024W/Vision4Ag/papers/Wu_The_New_Agronomists_Language_Models_are_Experts_in_Crop_Management_CVPRW_2024_paper.pdf" target="_blank">Read the paper</a> | 
        <a href="https://github.com/jingwu6/LM_AG" target="_blank">Code</a>
      </figcaption>
    </figure>
    <figure>
      <img src="images/residual.png" alt="Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks">
      <figcaption>
        <strong>Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks</strong><br>
        <em>Authors: Zhixin Lai*, <b>Jing Wu</b>*, Suiyao Chen, Yucheng Zhou, Naira Hovakimyan </em><br>
        <em>CVPRW 2024 <span style="color: red;">Oral</span>
</em><br>
        <a href="https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.pdf" target="_blank">Read the paper</a> | 
        <a href="https://github.com/ZhixinLai/LLMBoostMedical" target="_blank">Code</a>
      </figcaption>
    </figure>
    <figure>
      <img src="images/sparsegan.png" alt="Balanced Training for Sparse GANs">
      <figcaption>
        <strong>Balanced Training for Sparse GANs</strong><br>
        <em>Authors: Yite Wang*, <b>Jing Wu</b>*, Naira Hovakimyan, Ruoyu Sun </em><br>
        <em>NeurIPS 2023 </em><br>
        <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/2c28efa5a86dca4b603a36c08f49f240-Paper-Conference.pdf" target="_blank">Read the paper</a> | 
        <a href="https://github.com/YiteWang/ADAPT" target="_blank">Code</a>
      </figcaption>
    </figure>
    <figure>
      <img src="images/ExtendedAG.png" alt="Extended Agriculture-Vision Dataset for Agricultural Pattern Analysis">
      <figcaption>
        <strong>Extended Agriculture-Vision Dataset for Agricultural Pattern Analysis</strong><br>
        <em>Authors:  <b>Jing Wu</b>, David Pichler, Daniel Marley, David Wilson, Naira Hovakimyan, Jennifer Hobbs </em><br>
        <em>TMLR 2023 </em><br>
        <a href="https://arxiv.org/pdf/2303.02460" target="_blank">Read the paper</a> | 
        <a href="https://github.com/jingwu6/Extended-Agriculture-Vision-Dataset" target="_blank">Data</a>
      </figcaption>
    </figure>
    <figure>
      <img src="images/Hallucination.png" alt="Hallucination Improves Performance in Contrastive Learning">
      <figcaption>
        <strong>Hallucination Improves Performance in Contrastive Learning</strong><br>
        <em>Authors:  <b>Jing Wu</b>, Jennifer Hobbs, Naira Hovakimyan</em><br>
        <em>ICCV 2023 </em><br>
        <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.pdf" target="_blank">Read the paper</a> | 
        <a href="https://github.com/jingwu6/Hallucination-improves-the-performance-of-unsupervised-visual-representation-learning" target="_blank">Code</a>
      </figcaption>
    </figure>
  </div>
  <button class="carousel-btn prev-btn" onclick="moveSlides(-1)">&#10094;</button>
  <button class="carousel-btn next-btn" onclick="moveSlides(1)">&#10095;</button>
</div>

<script>
  let currentSlide = 0;
  const slides = document.querySelector('.slides');
  const totalSlides = slides.children.length;

  function moveSlides(n) {
    currentSlide = (currentSlide + n + totalSlides) % totalSlides;
    slides.style.transform = `translateX(-${currentSlide * 100}%)`;
  }
</script>

<style>
  .carousel {
    width: 100%;
    max-width: 800px;
    margin: 20px auto;
    position: relative;
    overflow: hidden;
  }

  .carousel img {
    width: 100%;
    max-height: 350px;
    object-fit: contain;
    display: block;
  }

  .slides {
    display: flex;
    transition: transform 0.5s ease-in-out;
    width: 100%;
  }

  figure {
    min-width: 100%;
    text-align: center;
    padding: 10px 0;
  }

  figcaption {
    font-size: 1em;
    color: #333;
    text-align: center;
  }

  .carousel-btn {
    position: absolute;
    top: 50%;
    transform: translateY(-50%);
    background-color: rgba(0, 0, 0, 0.5);
    color: white;
    border: none;
    padding: 10px;
    cursor: pointer;
  }

  .prev-btn {
    left: 10px;
  }

  .next-btn {
    right: 10px;
  }
</style>

