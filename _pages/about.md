---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

‚≠ê If you have opportunities or collaborations in mind, please feel free to reach out. ‚≠ê

I am currently an Applied Research Scientist at AWS, Amazon, working on Generative AI.

I got my **Ph.D.** from [**University of Illinois at Urbana-Champaign**](https://illinois.edu/), guided by [**Prof. Naira Hovakimyan**](https://naira.mechse.illinois.edu/sciencex_teams/naira-hovakimyan/). I've also been a research scientist in machine learning at [**Intelinair**](https://www.intelinair.com/), mentored by [**Jennifer Hobbs**](https://scholar.google.com/citations?user=zeWhseAAAAAJ&hl=en). Additionally, I interned as an applied research scientist at [**Amazon**](https://www.amazon.jobs/en/teams/buyer-risk-prevention).

## üîç **Research Interests**

My research is primarily in the fields of **LLM**, **computer vision** and **multi-modality learning**. In particular, I'm interested in exploring **improved representation learning** techniques to aid machines in comprehending the structure of massive amounts of unlabeled data.

In industry applications, my efforts are devoted to **remote sensing**, **robotics** and **sustainable agriculture**. My philosophy towards research is centered around bringing people's lives and AI technology together at scale. 



<!-- Scrollable News Section -->
<div class="news-container">
  <h2>üì∞ News & Updates</h2>
  <div class="news-updates">
    <ul>
      <li><strong>May 2024</strong>: I am pleased to announce the successful defense of my Ph.D. thesis.</li>
      <li><strong>April 2024</strong>:
        <ul>
          <li>Our paper, "The new agronomists: Language models are experts in crop management" has been accepted at <strong>CVPR in AgVision</strong>.</li>
          <li>Our paper, "Residual-based Language Models are Free Boosters for Biomedical Imaging" has been accepted at <strong>CVPR in AI-MIA</strong> as <strong>oral</strong> presentation.</li>
        </ul>
      </li>
      <li><strong>Jan 2024</strong>: Our paper, "SwitchTab: Switched Autoencoders Are Effective Tabular Learners" has been accepted at <strong>AAAI</strong>.</li>
      <li><strong>Oct 2023</strong>: Our work on "ReConTab: Regularized Contrastive Representation Learning for Tabular Data" has been accepted at <strong>NeurIPS</strong> workshop.</li>
      <li><strong>September 2023</strong>: Our paper titled "Balanced Training for Sparse GANs" has been accepted at <strong>NeurIPS</strong>.</li>
      <li><strong>July 2023</strong>: 
        <ul>
          <li>Our paper, "Hallucination Improves the Performance of Contrastive Learning," got accepted at <strong>ICCV</strong>. <a href="https://arxiv.org/pdf/2307.12168.pdf">Read the paper here</a>.</li>
          <li>Our work "GenCo: An Auxiliary Generator from Contrastive Learning for Enhanced Few-Shot Learning in Remote Sensing" received the <strong>spotlight</strong> at <strong>ECAI</strong>. <a href="https://arxiv.org/pdf/2307.14612.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>May 2023</strong>: I'm joining <strong>Amazon</strong> as an Intern Applied Research Scientist.</li>
      <li><strong>April 2023</strong>: 
        <ul>
          <li>Our research on "Optimizing Crop Management with Reinforcement Learning and Imitation Learning" has been accepted at <strong>IJCAI</strong>. <a href="https://arxiv.org/pdf/2209.09991.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>March 2023</strong>: 
        <ul>
          <li>New paper on <strong>Arxiv</strong> titled "Dynamic Sparse Training for GANs". <a href="https://arxiv.org/pdf/2302.14670.pdf">Read the paper here</a>.</li>
          <li>Our work "Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis" got accepted at <strong>TMLR</strong>. <a href="https://arxiv.org/pdf/2303.02460.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
      <li><strong>June 2022</strong>: Presented our research at <strong>CVPR</strong> in New Orleans.</li>
      <li><strong>May 2022</strong>: 
        <ul>
          <li>Our paper, "Optimizing Nitrogen Management with Deep Reinforcement Learning and Crop Simulations", was accepted for an <strong>oral</strong> presentation at <strong>CVPR in AgVision</strong>. <a href="https://arxiv.org/pdf/2204.10394.pdf">Read the paper here</a>.</li>
        </ul>
      </li>
    </ul>
  </div>
</div>

<!-- CSS to make the news section scrollable and align with previous titles -->
<style>
  .news-container {
    margin: 20px auto;
    width: 100%; /* Align width with previous titles */
    max-width: 800px; /* Adjust width to make it wider */
  }

  .news-updates {
    height: 250px; /* Adjust height for more content */
    overflow-y: scroll; /* Enable vertical scrolling */
    padding: 10px;
    border: 1px solid #ddd;
    background-color: #f9f9f9;
  }

  .news-updates ul {
    list-style-type: none;
    padding: 0;
  }

  .news-updates li {
    margin-bottom: 15px;
  }

  .news-updates li ul {
    margin-top: 5px;
  }

  .news-updates a {
    color: #0066cc;
    text-decoration: none;
  }

  .news-updates a:hover {
    text-decoration: underline;
  }
</style>




## üìë **Selected Publications**


<!-- Publication Carousel -->
<div class="publication-carousel">
  <div class="carousel-container">

    <!-- Carousel for switching between publications -->
    <div class="carousel-slides">
      
      <!-- First publication -->
      <div class="publication-slide">
        <div class="publication-image">
          <img src="images/Switch.png" alt="Paper 1">
        </div>
        <div class="publication-details">
          <h3>Switchtab: Switched autoencoders are effective tabular learners</h3>
          <p><i>Annual AAAI Conference on Artificial Intelligence (AAAI) 2024</i></p>
          <a class="publication-link" href="https://arxiv.org/pdf/2401.02013" target="_blank">arxiv</a> | <a class="publication-link" href="#" target="_blank">code</a>
        </div>
      </div>

      <!-- Second publication -->
      <div class="publication-slide">
        <div class="publication-image">
          <img src="images/sparsegan.png" alt="Paper 2">
        </div>
        <div class="publication-details">
          <h3>Balanced Training for Sparse GANs</h3>
          <p><i>Neural Information Processing Systems (NeurIPS) 2024</i></p>
          <a class="publication-link" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/2c28efa5a86dca4b603a36c08f49f240-Paper-Conference.pdf" target="_blank">arxiv</a> | <a class="publication-link" href="#" target="_blank">code</a>
        </div>
      </div>

      <!-- Third publication -->
      <div class="publication-slide">
        <div class="publication-image">
          <img src="images/residual.png" alt="Paper 3">
        </div>
        <div class="publication-details">
          <h3>Residual-based Language Models are Free Boosters for Biomedical Imaging Tasks</h3>
          <p><i>Conference on Computer Vision and Pattern Recognition Workshop (CVPRW) 2024</i></p>
          <a class="publication-link" href="https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Lai_Residual-based_Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks_CVPRW_2024_paper.pdf" target="_blank">arxiv</a> | <a class="publication-link" href="#" target="_blank">code</a>
        </div>
      </div>

    </div>

    <!-- Dots for navigation -->
    <div class="carousel-dots">
      <span class="dot" data-slide="0"></span>
      <span class="dot" data-slide="1"></span>
      <span class="dot" data-slide="2"></span>
    </div>

  </div>
</div>

<!-- Styles -->
<style>
  body {
    font-family: 'Roboto', sans-serif;
    background-color: #f9fafb;
  }

  .publication-carousel {
    display: flex;
    justify-content: center;
    align-items: center;
    margin: 50px auto;
    padding: 0;
    max-width: 1200px;
  }

  .carousel-container {
    display: flex;
    align-items: center;
    position: relative;
    overflow: hidden;
    width: 100%;
    height: 450px;
    background: #ffffff;
    border-radius: 10px;
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
    padding-bottom: 20px;
  }

  .carousel-slides {
    display: flex;
    transition: transform 0.6s ease-in-out;
    width: 300%;
  }

  .publication-slide {
    display: flex;
    align-items: center;
    justify-content: space-between;
    width: 100%;
    flex-shrink: 0;
    padding: 30px;
  }

  .publication-image img {
    width: 350px;
    height: auto;
    border-radius: 8px;
  }

  .publication-details {
    margin-left: 30px;
    color: #333;
    font-size: 0.9rem;
  }

  .publication-details h3 {
    font-size: 1.2rem;
    margin-bottom: 10px;
  }

  .publication-details p {
    font-size: 0.85rem;
    color: #555;
    margin-bottom: 15px;
  }

  .publication-link {
    text-decoration: none;
    color: #1a73e8;
    font-weight: 500;
  }

  .publication-link:hover {
    text-decoration: underline;
  }

  /* Dots styling */
  .carousel-dots {
    text-align: center;
    position: absolute;
    bottom: 10px;
    left: 50%;
    transform: translateX(-50%);
  }

  .dot {
    height: 15px;
    width: 15px;
    margin: 0 5px;
    background-color: #bbb;
    border-radius: 50%;
    display: inline-block;
    cursor: pointer;
  }

  .dot.active {
    background-color: #1a73e8;
  }

</style>

<!-- JavaScript -->
<script>
  let currentSlideIndex = 0;
  const slides = document.querySelector('.carousel-slides');
  const dots = document.querySelectorAll('.dot');
  const totalSlides = slides.children.length;

  // Move to the slide when dots are clicked
  function currentSlide(n) {
    currentSlideIndex = n;
    updateSlidePosition();
  }

  // Auto-slide every 5 seconds
  let autoSlideInterval = setInterval(() => {
    currentSlideIndex = (currentSlideIndex + 1) % totalSlides;
    updateSlidePosition();
  }, 5000);

  // Function to update the slide position and highlight the corresponding dot
  function updateSlidePosition() {
    slides.style.transform = `translateX(-${(currentSlideIndex * 100) / totalSlides}%)`;
    dots.forEach((dot, index) => {
      dot.classList.toggle('active', index === currentSlideIndex);
    });
  }

  // Add click event listeners to each dot to trigger the slide change
  dots.forEach(dot => {
    dot.addEventListener('click', () => {
      clearInterval(autoSlideInterval); // Stop auto-scroll on manual navigation
      currentSlide(dot.dataset.slide);
      autoSlideInterval = setInterval(() => { // Restart auto-scroll after manual navigation
        currentSlideIndex = (currentSlideIndex + 1) % totalSlides;
        updateSlidePosition();
      }, 5000);
    });
  });

  // Initial activation of the first dot
  dots[0].classList.add('active');
</script>


